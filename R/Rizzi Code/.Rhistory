# Estimation of smooth age at death distributions from grouped death counts
setwd("Q:/pclm R package")
source("pclm_source.r")
# DATA AND PREPARATION
# Read actual deaths counts by single-year of age from HMD, Sweden 2014
HMDSweden_deaths <- read.csv("HMDSweden_deaths.txt", sep="")
# Aggregate them artificially in 5-years age classes with 85+
# add last bin with 0 counts to complete the histogram
HMDSweden_deaths$Groups_Counts <- c(rep(1:17, each=5), rep(18,26))
a_g <- aggregate(HMDSweden_deaths$Total, by=list(HMDSweden_deaths$Groups_Counts), FUN="sum")
y_1 <- a_g$x
y <-  c(y_1,0)
# detailed grid for the underlying distribution
# we assume no deaths after the age of 115
m = 130
x = 1:m
# compute the group counts
# 5-year age classes with open-ended age class at 85
# close the histogram with bin of 0 counts where no deaths are expected
# here we should have a user-friendly and flexible way to insert the breaks
# addition of the bin with 0 counts at the right-hand side of the distribution is necessary for age-at-death distributions, especially if last bin is 85+
ilo_1 = seq(1, 86, by = 5)
ilo_2 = 116
ilo = c(ilo_1, ilo_2)
ihi = c(seq(5,85,5),115,130)
n = length(ihi)
ihi[n] = m
# intervals lengths
leng <- ihi-ilo+1
# make C matrix and (trivial) basis B
C = matrix(0, n, m)
for (i in 1:n) C[i, ilo[i] : ihi[i]] =  1
B = diag(m)
# Construct B-spline basis if detailed sequence to be estimated is > 130 (rule of thumb)
# library(MortalitySmooth)
# B <- MortSmooth_bbase(x=x, xl=min(x), xr=max(x),ndx=floor(m/5), deg=3) # ncol(B) = ndx + deg =
# rule of thumb: one knot for the B-spline basis each 4-5 observations.
lambda <- 10^seq(-2,7, .25)
lambda
AICs <- parallelsugar::mclapply(lambda, get.AIC, y=y,C=C,B=B,mc.cores = 4)
pclm <- function(y, C, X, lambda = 1, deg = 2, show = F){
# Fit a PCLM (estimate b in ) E(y) = C %*% exp(X %*% b)
# y = the vector of observed counts of length i
# C = the composition matrix of dimension IxJ
# X = the identity matrix of dimension JxJ; or B-spline basis
# lambda = smoothing parameter
# deg = order of differences of the components of b
# show = indicates whether iteration details should be shown
# Some preparations
nx <- dim(X)[2]
D <- diff(diag(nx), diff = deg)
bstart <- log(sum(y) / nx);
b <- rep(bstart, nx);
# Perform the iterations
for (it in 1:50) {
b0 <- b
eta <- X %*% b
gam <- exp(eta)
mu <- C %*% gam
w <- c(1 / mu, rep(lambda, nx - deg))
Gam <- gam %*% rep(1, nx)
Q <- C %*% (Gam * X)
z <- c(y - mu + Q %*% b, rep(0, nx - deg))
Fit <- lsfit(rbind(Q, D), z, wt = w, intercept = F)
b <- Fit$coef
db <- max(abs(b - b0))
if (show)  cat(it, " ", db, "\n")
if (db < 1e-6) break
}
# cat(it, "  ", db, "\n")
# Regression diagnostics
R <- t(Q) %*% diag(c(1 / mu)) %*% Q
H <- solve(R + lambda * t(D) %*% D, R)
H0 <- solve(R + lambda * t(D) %*% D) # variance-covariance matrix Bayesian approach
H1 <- H0 %*% R %*% H0 # variance-covaraince matrix sandwitch estimator
fit <- list()
fit$trace <- sum(diag(H))
ok <- y > 0
fit$dev <- 2 * sum(y[ok] * log(y[ok] / mu[ok]))
fit$gamma <- gam
fit$aic <- fit$dev + 2 * fit$trace
fit$bic <- fit$dev + log(length(y)) * fit$trace
fit$mu <- mu
fit$H0 <- H0
fit$H1 <- H1
fit$eta <- eta
fit
}
get.AIC <- function( lambda = lambda, ...){
mod <- pclm(y,C,B,lambda,deg = 2)
mod$aic
}
AICs <- parallelsugar::mclapply(lambda, get.AIC, y=y,C=C,B=B,mc.cores = 4)
AICs
unlist(AICs)
lambda.hat <- lambda[which.min(AICs)]
AICs <- parallelsugar::mclapply(lambda, get.AIC, y=y,C=C,B=B,mc.cores = 4)
Single_COD_fun(y)
Single_COD_fun<- function(y2){
# some parameters
y <- y2[-1]
m  <- 110
x  <- 1:m
gr <- c(1,seq(5,80,5))
n  <- length(gr)
# Make C matrix and (trivial) basis B
C                <- matrix(0, n, m)
C[1,1:4]         <- 1
C[2:(n-1),5:79]  <- kronecker(diag(n-2), matrix(1, 1, 5))
C[n, 80:110]   <- 1
B <- diag(m)
lambda <- 10^seq(-2,7, .25)
AICs <- parallelsugar::mclapply(lambda, get.AIC, y=y,C=C,B=B,mc.cores = 4)
unlist(AICs)
lambda.hat <- lambda[which.min(AICs)]
# or use alternatively BIC, especially indicated for large sample sizes because AIC has the tendency to undersmooth
# solve the PCLM
mod = pclm(y, C, B,lambda = lambda.hat, deg = 2)
c(y2[1],mod$gamma)
}
Single_COD_fun(y)
# Estimation of smooth mortality rates from grouped mortality counts
setwd("Q:/pclm R package")
source("pclm_source.r")
# DATA AND PREPARATION
# Read actual deaths counts by single-year of age from HMD, Sweden 2014
HMDSweden_deaths <- read.csv("HMDSweden_deaths.txt", sep="")
# Aggregate them artificially in 5-years age classes with 85+
HMDSweden_deaths$Groups_Counts <- c(rep(1:17, each=5), rep(18,26))
a_g <- aggregate (HMDSweden_deaths$Total, by=list(HMDSweden_deaths$Groups_Counts), FUN="sum")
y <- a_g$x # for rates no bin with 0 counts!!
# Read actual exposures in single year age classes.
# if also exposures are grouped, ungrouped them first with the pclm!
HMDSweden_exposures <- read.csv("HMDSweden_exposures.txt", sep="")
E = as.matrix(HMDSweden_exposures$Total)
# Define the detailed grid where to estimate the underlying density
m = 111
x = 1:m
# Compute the group counts, i.e. 5-years age classes with 85+
ilo = seq(1, 86, by = 5)
ihi = ilo + 4
n = length(ihi)
ihi[n] = m
# intervals lengths
leng <- ihi-ilo+1
# Make C matrix and (trivial) basis B
C0 = matrix(0, n, m)
for (i in 1:n) C0[i, ilo[i] : ihi[i]] =  1
Cp = C0%*%diag(c(E)) # multiply C matrix by exposures as offset
B = diag(m)
# SOLVE THE PCLM
lambda <- 10^seq(-2,7,.25)
nl <- length(lambda)
AICs <- numeric(nl)
for(j in 1:nl){
mod = pclm(y, Cp, B,lambda = lambda[j], deg = 2)
AICs[j] <- mod$aic
}
lambda.hat <- lambda[which.min(AICs)]
mod = pclm(y, Cp, B,lambda = lambda.hat, deg = 2)
cat('lambda.hat, ED & AIC:', lambda.hat, mod$trace, mod$aic, '\n')
plot(0:110, log10(mod$gamma), type="l", col="red", lwd=2,
ylab="Death Rates (log10)", xlab="Age",
main="Death rates, Sweden 2014.
Source: HMD")
# true empirical rates
lines(0:110, log10(HMDSweden_deaths$Total/HMDSweden_exposures$Total), type="o", col="blue")
